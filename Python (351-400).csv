#,Type,Scenario Name,Problem Summary,Prerequisites,Tool Features,Success Criteria,Min Pass,Deliverables,Chain/Category
351,🆕 NEW,Python Environment Setup,"Data analyst starting with Python. Install Python, Jupyter Notebook/Lab, essential libraries (pandas, numpy, matplotlib). Verify installation, run first Python commands. Foundation for all Python work.",None - fresh Python installation,"Python installation, pip, Jupyter Notebook/Lab, conda/venv, import statements, print(), basic Python syntax","10 criteria, 100 pts",80 pts,"Jupyter notebook with successful imports, version checks, ""Hello World"" output, installation documentation (200 words)",Python Basics - START
352,🆕 NEW,Load CSV with Pandas,Sales data in CSV file. Use pandas to load into DataFrame for analysis. First step in Python data workflow - getting data in.,None - create sample sales CSV file,"pandas, pd.read_csv(), DataFrame basics, .head(), .info(), .describe(), file paths","10 criteria, 100 pts",80 pts,"Jupyter notebook loading CSV, DataFrame displayed, data exploration commands, documentation (150 words)",Python Pandas - START
353,🔗 CONTINUES,Data Exploration Basics,"Loaded DataFrame needs inspection. Use .head() (first rows), .tail() (last rows), .info() (data types, nulls), .describe() (statistics), .shape (dimensions). Understanding your data.",Assignment #352 (loaded DataFrame),".head(), .tail(), .info(), .describe(), .shape, .columns, .dtypes, data exploration methods","10 criteria, 100 pts",80 pts,"Jupyter notebook with all exploration commands, outputs displayed, documentation (150 words)",Python Pandas
354,🔗 CONTINUES,Filter Rows with Boolean Indexing,"Sales DataFrame: need only high-value sales (>$1000). Boolean indexing: df[df[""Amount""] > 1000] creates filtered subset. Like SQL WHERE.",Assignment #352 (sales DataFrame),"Boolean indexing, comparison operators, df[condition], combining conditions with & and |, .loc[]","11 criteria, 100 pts",80 pts,"Jupyter notebook with filtering examples, filtered DataFrames, documentation (200 words)",Python Pandas
355,🔗 CONTINUES,Select Specific Columns,"Large DataFrame with 20 columns, need only Name, Date, Amount. Column selection: df[[""Name"", ""Date"", ""Amount""]] creates subset DataFrame.",Assignment #352 (DataFrame),"Column selection, single column (Series), multiple columns (DataFrame), .loc for rows and columns","9 criteria, 100 pts",75 pts,"Jupyter notebook with column selection, subset DataFrames, documentation (150 words)",Python Pandas
356,🔗 CONTINUES,Sort Data,"Sort sales by Amount descending (highest first), then by Date ascending. sort_values() handles sorting with multiple keys.",Assignment #352 (sales DataFrame),".sort_values(), by parameter, ascending parameter, inplace parameter, multi-column sorting","10 criteria, 100 pts",80 pts,"Jupyter notebook with sorting examples, sorted DataFrames, documentation (150 words)",Python Pandas
357,🔗 CONTINUES,Handle Missing Values,"Dataset has NaN (missing values). Options: drop rows with .dropna(), fill with .fillna(value), check with .isnull(). Data cleaning essential.",Assignment #352 (create data with missing values),".isnull(), .notnull(), .dropna(), .fillna(), missing value strategies, axis parameter","11 criteria, 100 pts",80 pts,"Jupyter notebook showing missing value handling, before/after comparison, documentation (200 words)",Python Pandas
358,🔗 CONTINUES,Group By and Aggregate,"Sales by product category. df.groupby(""Category"")[""Sales""].sum() aggregates. Like SQL GROUP BY. Powerful analysis tool.",Assignment #352 (sales with categories),".groupby(), aggregation functions (sum, mean, count, min, max), .agg(), multiple aggregations","12 criteria, 100 pts",85 pts,"Jupyter notebook with groupby examples, aggregated results, documentation (200 words)",Python Pandas
359,🔗 CONTINUES,Create New Calculated Column,"DataFrame has Revenue and Cost. Add Profit column: df[""Profit""] = df[""Revenue""] - df[""Cost""]. Calculated fields.",Assignment #352 (DataFrame with numeric columns),"Creating columns, arithmetic operations, df[""new_col""] = expression, vectorized operations","9 criteria, 100 pts",75 pts,"Jupyter notebook with new column creation, calculations shown, documentation (150 words)",Python Pandas
360,🔗 CONTINUES,Basic Plotting with Pandas,"Visualize sales trend over time. df[""Sales""].plot() creates line chart. Quick visualization from DataFrame.",Assignment #352 (time series data),".plot(), plot types (line, bar, scatter, hist), matplotlib integration, basic customization","10 criteria, 100 pts",80 pts,"Jupyter notebook with plots displayed, various chart types, documentation (150 words)",Python Visualization - START
361,🆕 NEW,Bar Chart with Matplotlib,Product categories with sales totals. Create bar chart showing category comparison. Matplotlib for custom visualization.,None - create category sales data,"matplotlib.pyplot, plt.bar(), x/y parameters, labels, title, plt.show(), customization","10 criteria, 100 pts",80 pts,"Jupyter notebook with bar chart code and output, customized chart, documentation (150 words)",Python Visualization
362,🆕 NEW,Line Chart for Trends,Monthly revenue over 12 months. Line chart shows trend. plt.plot() connects points showing progression.,None - create time series data,"plt.plot(), line styles, markers, colors, xlabel/ylabel, title, legend, grid","10 criteria, 100 pts",80 pts,"Jupyter notebook with line chart, trend visualization, documentation (150 words)",Python Visualization
363,🆕 NEW,Scatter Plot for Correlation,Advertising spend vs Sales revenue. Scatter plot shows relationship. Each point = one observation.,None - create paired data,"plt.scatter(), point sizes, colors, alpha transparency, relationship visualization","10 criteria, 100 pts",80 pts,"Jupyter notebook with scatter plot, correlation visible, documentation (150 words)",Python Visualization
364,🆕 NEW,Histogram for Distribution,"Test scores for 100 students. Histogram shows frequency distribution. How many scored 0-10, 11-20, etc.",None - create test scores,"plt.hist(), bins parameter, frequency distribution, density curves, range","10 criteria, 100 pts",80 pts,"Jupyter notebook with histogram, distribution visible, documentation (150 words)",Python Visualization
365,🔗 CONTINUES,Join/Merge DataFrames,"Two DataFrames: Orders (CustomerID, Amount) and Customers (CustomerID, Name). Merge on CustomerID. Like SQL JOIN.",Assignment #352 extended - create two tables,"pd.merge(), on parameter, how parameter (left/right/inner/outer), merge types, join keys","12 criteria, 100 pts",85 pts,"Jupyter notebook with merge examples, joined DataFrames, documentation (200 words)",Python Pandas
366,🔗 CONTINUES,Concatenate DataFrames,"Q1, Q2, Q3, Q4 sales in separate DataFrames (same structure). pd.concat() stacks vertically. Combining data.",Assignment #352 - create quarterly DataFrames,"pd.concat(), axis parameter (0=rows, 1=columns), ignore_index, stacking DataFrames","10 criteria, 100 pts",80 pts,"Jupyter notebook with concatenation, stacked result, documentation (150 words)",Python Pandas
367,🔗 CONTINUES,Pivot Table in Pandas,"Cross-tabulation: Regions as rows, Products as columns, Sales as values. df.pivot_table() like Excel pivot.",Assignment #352 (sales data),".pivot_table(), values, index, columns, aggfunc, fill_value, pivot analysis","11 criteria, 100 pts",80 pts,"Jupyter notebook with pivot table, cross-tabulation result, documentation (200 words)",Python Pandas
368,🔗 CONTINUES,Export to CSV,"Analysis complete, save results. df.to_csv(""output.csv"") writes DataFrame to file. Sharing results.",Assignment #352 (any DataFrame),".to_csv(), index parameter, header parameter, file paths, encoding, saving data","8 criteria, 100 pts",75 pts,"Jupyter notebook with export code, CSV file created, documentation (100 words)",Python Pandas
369,🆕 NEW,String Operations on Series,"Customer names need uppercase. df[""Name""].str.upper() applies to all. Text manipulation in pandas.",None - create DataFrame with text data,".str accessor, .upper(), .lower(), .contains(), .replace(), .strip(), string methods","10 criteria, 100 pts",80 pts,"Jupyter notebook with string operations, transformed text, documentation (150 words)",Python Pandas
370,🆕 NEW,Date Operations,"Date column as string ""2024-01-15"". Convert to datetime, extract year, month, day. pd.to_datetime() and .dt accessor.",None - create DataFrame with date strings,"pd.to_datetime(), .dt accessor, .dt.year, .dt.month, .dt.day, date parsing","11 criteria, 100 pts",80 pts,"Jupyter notebook with date operations, extracted components, documentation (200 words)",Python Pandas
371,🔗 CONTINUES,Advanced Filtering with Multiple Conditions,"Complex filter: (Sales > 1000) AND (Region == ""East"") OR (Product == ""Premium""). Combining boolean conditions with & and |.",Assignment #352 (sales data),"Boolean operators (&, |, ~), parentheses for precedence, .isin(), complex conditions","11 criteria, 100 pts",80 pts,"Jupyter notebook with complex filters, logical combinations, documentation (200 words)",Python Pandas - Intermediate
372,🔗 CONTINUES,Apply Custom Functions,"Custom calculation per row: categorize sales as ""Small""/""Medium""/""Large"". df[""Category""] = df[""Amount""].apply(categorize_func).",Assignment #352 (sales data),".apply(), lambda functions, custom functions, axis parameter, row-wise vs column-wise operations","12 criteria, 100 pts",85 pts,"Jupyter notebook with apply examples, custom functions, documentation (200 words)",Python Pandas - Intermediate
373,🔗 CONTINUES,Multiple Aggregations per Group,"Sales by product: need sum, mean, count, min, max all together. .agg() with dictionary or list of functions.",Assignment #352 (sales data),".agg() with multiple functions, dictionary for different columns, named aggregations","11 criteria, 100 pts",80 pts,"Jupyter notebook with multiple aggregations, comprehensive summary, documentation (200 words)",Python Pandas - Intermediate
374,🔗 CONTINUES,Rolling Window Calculations,"7-day moving average of daily sales. df[""Sales""].rolling(7).mean() creates smoothed trend.",Assignment #352 (daily time series),".rolling(), window size, aggregation functions, centered windows, min_periods","11 criteria, 100 pts",80 pts,"Jupyter notebook with rolling calculations, smoothed trend chart, documentation (200 words)",Python Pandas - Intermediate
375,🔗 CONTINUES,Reshape with Melt (Wide to Long),"Wide format: columns Jan, Feb, Mar... Need long: Month, Value. pd.melt() transforms.",Assignment #352 - create wide format data,"pd.melt(), id_vars, value_vars, var_name, value_name, reshaping data","11 criteria, 100 pts",80 pts,"Jupyter notebook with melt transformation, long format result, documentation (200 words)",Python Pandas - Intermediate
376,🔗 CONTINUES,Reshape with Pivot (Long to Wide),"Long format: Product, Metric (Revenue/Cost/Profit), Value. pivot() creates wide: Product, Revenue, Cost, Profit columns.",Assignment #352 - create long format data,".pivot(), index, columns, values, wide format creation, pivot vs pivot_table","11 criteria, 100 pts",80 pts,"Jupyter notebook with pivot transformation, wide format result, documentation (200 words)",Python Pandas - Intermediate
377,🔗 CONTINUES,Time Series Resampling,"Daily sales data. Resample to monthly totals: df.resample(""M"").sum(). Time aggregation.",Assignment #352 (daily data with datetime index),".resample(), frequency strings (D/W/M/Q/Y), aggregation after resampling, set_index for datetime","11 criteria, 100 pts",80 pts,"Jupyter notebook with resampling, monthly aggregation, documentation (200 words)",Python Pandas - Intermediate
378,🔗 CONTINUES,Correlation Matrix,"Multiple variables: Sales, Advertising, Price, Competition. df.corr() calculates correlation matrix. See relationships.",Assignment #352 - create multi-variable data,".corr(), correlation coefficients, interpreting correlation, selecting numeric columns only","10 criteria, 100 pts",80 pts,"Jupyter notebook with correlation matrix, heatmap visualization, documentation (200 words)",Python Pandas - Intermediate
379,🆕 NEW,Seaborn Heatmap Visualization,Correlation matrix from #378. Visualize with seaborn heatmap - color-coded correlation strength. Beautiful visualization.,Assignment #378 (correlation matrix),"seaborn, sns.heatmap(), annot, cmap, correlation visualization, advanced plotting","11 criteria, 100 pts",80 pts,"Jupyter notebook with seaborn heatmap, correlation visualized, documentation (200 words)",Python Visualization - Advanced
380,🆕 NEW,Categorical Encoding for ML,"Category column (""Small""/""Medium""/""Large"") needs numeric encoding for machine learning. pd.get_dummies() or LabelEncoder.",None - create categorical data,"pd.get_dummies(), LabelEncoder from sklearn, one-hot encoding, ordinal encoding, dummy variables","11 criteria, 100 pts",80 pts,"Jupyter notebook with encoding examples, encoded data, documentation (200 words)",Python ML Prep - START
381,🆕 NEW,Outlier Detection,Sales data has outliers (unusually high/low values). Use IQR method or z-score to identify outliers. Data quality analysis.,None - create data with outliers,"IQR calculation, quartiles, z-score, outlier thresholds, .quantile(), statistical outlier detection","11 criteria, 100 pts",80 pts,"Jupyter notebook with outlier detection, identified outliers, documentation (200 words)",Python Data Quality
382,🆕 NEW,Feature Standardization,"Machine learning needs features on same scale. StandardScaler transforms to mean=0, std=1. Feature scaling.",None - create numeric features,"StandardScaler from sklearn, fit_transform(), normalization vs standardization, scaling importance","10 criteria, 100 pts",80 pts,"Jupyter notebook with scaling, before/after distributions, documentation (200 words)",Python ML Prep
383,🆕 NEW,Train-Test Split,"Preparing for ML: split data 80% training, 20% testing. train_test_split() from sklearn. Model evaluation setup.",None - create dataset,"train_test_split from sklearn.model_selection, test_size, random_state, stratify, X/y split","10 criteria, 100 pts",80 pts,"Jupyter notebook with train-test split, split sizes verified, documentation (200 words)",Python ML Prep
384,🆕 NEW,Linear Regression Model,"Predict sales from advertising spend. Linear regression model: fit line through data, make predictions. First ML model.",Assignment #383 (train-test split data),"LinearRegression from sklearn, .fit(), .predict(), coefficients, intercept, basic ML workflow","12 criteria, 100 pts",85 pts,"Jupyter notebook with linear regression, predictions, model coefficients, documentation (250 words)",Python ML - START
385,🔗 CONTINUES,Model Evaluation Metrics,"Regression model needs evaluation. Calculate R², MAE (Mean Absolute Error), RMSE (Root Mean Squared Error). Measure accuracy.",Assignment #384 (fitted model),"R² score, mean_absolute_error, mean_squared_error, RMSE calculation, metrics interpretation","11 criteria, 100 pts",80 pts,"Jupyter notebook with all metrics calculated, interpretation, documentation (200 words)",Python ML
386,🆕 NEW,Logistic Regression Classification,Binary classification: predict customer churn (Yes/No). Logistic regression for classification problems.,None - create binary classification data,"LogisticRegression from sklearn, binary classification, .predict_proba(), classification workflow","12 criteria, 100 pts",85 pts,"Jupyter notebook with logistic regression, predictions, probabilities, documentation (250 words)",Python ML
387,🔗 CONTINUES,Classification Metrics,"Classification model evaluation: accuracy, precision, recall, F1-score, confusion matrix. Understanding model performance.",Assignment #386 (classification model),"accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report, metric interpretation","12 criteria, 100 pts",85 pts,"Jupyter notebook with all classification metrics, confusion matrix visualized, documentation (250 words)",Python ML
388,🆕 NEW,Cross-Validation,Single train-test split might be lucky/unlucky. Cross-validation: 5-fold CV gives robust performance estimate.,Assignment #384 or #386 (ML model),"cross_val_score, KFold, StratifiedKFold, cross-validation concept, CV scores interpretation","11 criteria, 100 pts",80 pts,"Jupyter notebook with cross-validation, CV scores, mean/std calculation, documentation (200 words)",Python ML
389,🆕 NEW,Feature Importance Analysis,Random Forest or Tree model: which features most important? .feature_importances_ shows importance scores.,None - create classification/regression data with multiple features,"RandomForestClassifier/Regressor, .feature_importances_, feature selection, importance visualization","11 criteria, 100 pts",80 pts,"Jupyter notebook with feature importance, ranked features, bar chart, documentation (200 words)",Python ML
390,🆕 NEW,Save and Load ML Model,"Trained model needs persistence. joblib.dump() saves model to file, joblib.load() loads it later. Model deployment prep.",Assignment #384 or #386 (trained model),"joblib from sklearn, .dump(), .load(), pickle alternative, model persistence","9 criteria, 100 pts",75 pts,"Jupyter notebook with save/load code, model file created, loaded model working, documentation (150 words)",Python ML
391,🆕 NEW,API Data Extraction,"Pull data from web API (weather, stocks, public API). requests library, JSON parsing, load into DataFrame. Real-world data source.",None - identify public API,"requests library, .get(), .json(), API authentication, rate limits, error handling","13 criteria, 100 pts",85 pts,"Jupyter notebook with API call, JSON to DataFrame, working code, documentation (250 words)",Python Advanced - START
392,🆕 NEW,Web Scraping,"Extract data from website tables. BeautifulSoup parses HTML, extracts table data into DataFrame. Web data extraction.",None - identify scrapeable website,"BeautifulSoup, requests, HTML parsing, find/find_all, ethical scraping, robots.txt","13 criteria, 100 pts",85 pts,"Jupyter notebook with scraping code, extracted data, documentation (300 words on ethics/legality)",Python Advanced
393,🆕 NEW,Database Connection,"Connect to SQL database (SQLite/PostgreSQL/MySQL). Query database, load results into DataFrame. Enterprise data source.",None - create/access database,"SQLAlchemy, create_engine, pd.read_sql(), pd.read_sql_query(), database connections","12 criteria, 100 pts",85 pts,"Jupyter notebook with database connection, query results, documentation (250 words)",Python Advanced
394,🆕 NEW,Automated PDF Report Generation,Analysis complete. Generate PDF report with charts and tables automatically. matplotlib + reportlab or similar.,Assignment #360+ (charts and data),"matplotlib savefig, reportlab or fpdf, PDF generation, report automation","13 criteria, 100 pts",85 pts,"Jupyter notebook with PDF generation code, generated PDF file, documentation (250 words)",Python Advanced
395,🆕 NEW,Interactive Dashboard with Plotly Dash,"Create web dashboard: dropdowns filter data, charts update interactively. Dash app for stakeholder use.",Assignment #352+ (sales data),"Dash, app.layout, callbacks, interactive components, web dashboard basics","14 criteria, 100 pts",90 pts,"Python script with Dash app, screenshot of running dashboard, documentation (300 words)",Python Advanced - Dashboards
396,🆕 NEW,Natural Language Processing Basics,"Customer reviews sentiment analysis. NLTK or spaCy for text processing, sentiment scoring. NLP introduction.",None - create text data (reviews),"NLTK or spaCy, tokenization, stopwords, sentiment analysis, text preprocessing","13 criteria, 100 pts",85 pts,"Jupyter notebook with NLP code, sentiment scores, documentation (250 words)",Python Advanced - NLP
397,🆕 NEW,Time Series Forecasting,"Monthly sales data. Forecast next 6 months using ARIMA, Prophet, or LSTM. Predictive analytics.",None - create time series data,"ARIMA from statsmodels, Prophet from fbprophet, forecasting, confidence intervals, model evaluation","14 criteria, 100 pts",90 pts,"Jupyter notebook with forecast model, predictions with intervals, visualization, documentation (300 words)",Python Advanced - ML
398,🆕 NEW,Clustering - Customer Segmentation,Unsupervised learning: group customers by behavior (RFM). K-Means clustering identifies segments.,None - create customer behavioral data,"KMeans from sklearn, elbow method, silhouette score, cluster interpretation, unsupervised learning","13 criteria, 100 pts",85 pts,"Jupyter notebook with clustering, segments identified, visualization, documentation (250 words)",Python Advanced - ML
399,🆕 NEW,Dimensionality Reduction with PCA,Dataset with 20 features. PCA reduces to 2-3 principal components for visualization. Feature extraction.,None - create high-dimensional data,"PCA from sklearn, n_components, explained_variance_ratio_, dimensionality reduction, visualization","12 criteria, 100 pts",85 pts,"Jupyter notebook with PCA, reduced dimensions, variance explained, documentation (250 words)",Python Advanced - ML
400,🆕 NEW,Ensemble Methods - Model Stacking,"Improve predictions: combine Random Forest, Gradient Boosting, XGBoost. Ensemble methods outperform single models.",Assignment #384/386 extended,"RandomForestClassifier, GradientBoostingClassifier, XGBoost, VotingClassifier, ensemble methods","14 criteria, 100 pts",90 pts,"Jupyter notebook with ensemble models, performance comparison, best model identified, documentation (300 words)",Python Advanced - ML
